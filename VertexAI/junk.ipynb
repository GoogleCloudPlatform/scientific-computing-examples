{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make folder for Python training script\n",
    "! rm -rf custom\n",
    "! mkdir custom\n",
    "\n",
    "# Add package information\n",
    "! touch custom/README.md\n",
    "\n",
    "setup_cfg = \"[egg_info]\\n\\ntag_build =\\n\\ntag_date = 0\"\n",
    "! echo \"$setup_cfg\" > custom/setup.cfg\n",
    "\n",
    "setup_py = \"import setuptools\\n\\nsetuptools.setup(\\n\\n    install_requires=[\\n\\n        'cloudml-hypertune',\\n\\n    ],\\n\\n    packages=setuptools.find_packages())\"\n",
    "! echo \"$setup_py\" > custom/setup.py\n",
    "\n",
    "pkg_info = \"Metadata-Version: 1.0\\n\\nName: Iris tabular classification\\n\\nVersion: 0.0.0\\n\\nSummary: Demostration training script\\n\\nHome-page: www.google.com\\n\\nAuthor: Google\\n\\nAuthor-email: aferlitsch@google.com\\n\\nLicense: Public\\n\\nDescription: Demo\\n\\nPlatform: Vertex\"\n",
    "! echo \"$pkg_info\" > custom/PKG-INFO\n",
    "\n",
    "# Make the training subfolder\n",
    "! mkdir custom/trainer\n",
    "! touch custom/trainer/__init__.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile custom/trainer/task.py\n",
    "import datetime\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import hypertune\n",
    "import argparse\n",
    "import logging\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--model-dir', dest='model_dir',\n",
    "                    default=os.getenv('AIP_MODEL_DIR'), type=str, help='Model dir.')\n",
    "parser.add_argument(\"--dataset-data-url\", dest=\"dataset_data_url\",\n",
    "                    type=str, help=\"Download url for the training data.\")\n",
    "parser.add_argument(\"--dataset-labels-url\", dest=\"dataset_labels_url\",\n",
    "                    type=str, help=\"Download url for the training data labels.\")\n",
    "parser.add_argument(\"--boost-rounds\", dest=\"boost_rounds\",\n",
    "                    default=20, type=int, help=\"Number of boosted rounds\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "def get_data():\n",
    "    logging.info(\"Downloading training data and labelsfrom: {}, {}\".format(args.dataset_data_url, args.dataset_labels_url))\n",
    "    # gsutil outputs everything to stderr so we need to divert it to stdout.\n",
    "    subprocess.check_call(['gsutil', 'cp', args.dataset_data_url, 'data.csv'], stderr=sys.stdout)\n",
    "    # gsutil outputs everything to stderr so we need to divert it to stdout.\n",
    "    subprocess.check_call(['gsutil', 'cp', args.dataset_labels_url, 'labels.csv'], stderr=sys.stdout)\n",
    "\n",
    "\n",
    "    # Load data into pandas, then use `.values` to get NumPy arrays\n",
    "    data = pd.read_csv('data.csv').values\n",
    "    labels = pd.read_csv('labels.csv').values\n",
    "\n",
    "    # Convert one-column 2D array into 1D array for use with XGBoost\n",
    "    labels = labels.reshape((labels.size,))\n",
    "\n",
    "    train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size=0.2, random_state=7)\n",
    "\n",
    "    # Load data into DMatrix object\n",
    "    dtrain = xgb.DMatrix(train_data, label=train_labels)\n",
    "    return dtrain, test_data, test_labels\n",
    "\n",
    "def train_model(dtrain):\n",
    "    logging.info(\"Start training ...\")\n",
    "    # Train XGBoost model\n",
    "    model = xgb.train({}, dtrain, num_boost_round=args.boost_rounds)\n",
    "    logging.info(\"Training completed\")\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, test_data, test_labels):\n",
    "    dtest = xgb.DMatrix(test_data)\n",
    "    pred = model.predict(dtest)\n",
    "    predictions = [round(value) for value in pred]\n",
    "    # evaluate predictions\n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "    logging.info(f\"Evaluation completed with model accuracy: {accuracy}\")\n",
    "\n",
    "    # report metric for hyperparameter tuning\n",
    "    hpt = hypertune.HyperTune()\n",
    "    hpt.report_hyperparameter_tuning_metric(\n",
    "        hyperparameter_metric_tag='accuracy',\n",
    "        metric_value=accuracy\n",
    "    )\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "dtrain, test_data, test_labels = get_data()\n",
    "model = train_model(dtrain)\n",
    "accuracy = evaluate_model(model, test_data, test_labels)\n",
    "\n",
    "# GCSFuse conversion\n",
    "gs_prefix = 'gs://'\n",
    "gcsfuse_prefix = '/gcs/'\n",
    "if args.model_dir.startswith(gs_prefix):\n",
    "    args.model_dir = args.model_dir.replace(gs_prefix, gcsfuse_prefix)\n",
    "    dirpath = os.path.split(args.model_dir)[0]\n",
    "    if not os.path.isdir(dirpath):\n",
    "        os.makedirs(dirpath)\n",
    "\n",
    "# Export the classifier to a file\n",
    "gcs_model_path = os.path.join(args.model_dir, 'model.bst')\n",
    "logging.info(\"Saving model artifacts to {}\". format(gcs_model_path))\n",
    "model.save_model(gcs_model_path)\n",
    "\n",
    "logging.info(\"Saving metrics to {}/metrics.json\". format(args.model_dir))\n",
    "gcs_metrics_path = os.path.join(args.model_dir, 'metrics.json')\n",
    "with open(gcs_metrics_path, \"w\") as f:\n",
    "    f.write(f\"{'accuracy: {accuracy}'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
